# Учебный проект модуля "Машинное обучение для текстов". Классификация комментариев
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

## Цель проекта:
На основании заранее размеченного корпуса текстов (предостален в csv файле) построить модель классификации комментариев пользователей на "токсичные" и "позитивные". Показателем качества модели принять F1-меру, которую максимизировать с граничным значением 0.75 на тестовых данных. 

## В процессе исследования решены следующие задачи:
1.  Исследованы загруженные данные
2.  Выполнен EDA, включая:
  - проверку корректности назначенных типов данных (ничего не меняли)
  - удаление неинформативных столбцов ('Unnamed:0')
  - изучение текстовой информации (тексты содержат излишне повторяющиеся символы, "мусорные" символы, строчные и прописные символы, пробелы)
  - проверка сбалансированности целевой переменной (переменная не сбалансирована)
3.  Исключен дисбаланас целевой переменной за счет удаления части "нетоксичных" строк.
4.  Проведена подготовка данных к машинному обучению, тексты отчищены:
  - от повторяющих более 3-х раз подряд символов
  - от мусорных символов (;$& и т.д.)
  - от лишних пробелов
  - от стоп-слов
5.  Тексты лемматизированы
6.  Для текстов посчитаны матрицы TF-IDF (статистическая мера, используемая для оценки важности слова в контексте документа). Размерность матрицы снижена за счет удаления редких слов (менее 3 вхождений)
7.  Построено облако слов
8.  Для текстов локально посчитаны и загружены через google-диск эмбендинги предъобученной модели BERT
9.  Подготовлены функции, автоматизирующие:
  - предобратотку текстов
  - расчет, считывание и запись эмбендингов
  - перебор гиперпараметров на основе метода GridSearch и кросс-валидации
  - фиксацию результатоввычислений в отдельных ДФ
10.  Проведено машинное обучение:
  - использованы модели:
    - LogisticRegression
    - RandomForestClassifier
    - HistGradientBoostingClassifie
    - KNeighborsClassifier
  - подобраны гиперпараметры для указанных моделей
  - оценена метрика качества, полученная на обучающей выборке, 
  - модель с оптимальными гиперпараметрами проверены на тестовой выборке.
11.  По результатам сравнение результатов, установлено, что лучшей моделью является LightGBM c F1 на тестовой выборке 0.78
12.  Результаты лучшей модели визуализированы ROC_AUC кривой
