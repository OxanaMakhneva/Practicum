# Учебный проект модуля "Машинное обучение для текстов". Классификация комментариев
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

## Цель проекта:
На основании заранее размеченного корпуса текстов (предостален в csv файле) построить модель классификации комментариев пользователей на "токсичные" и "позитивные". Показателем качества модели принять F1-меру, которую максимизировать с граничным значением 0.75 на тестовых данных. 

## В процессе исследования решены следующие задачи:
1. Исследованы загруженные данные
2. Выполнен EDA, включая:
  - проверку корректности назначенных типов данных (ничего не меняли)
  - удаление неинформативных столбцов ('Unnamed:0')
  - изучение текстовой информации (тексты содержат излишне повторяющиеся символы, "мусорные" символы, строчные и прописные символы, пробелы)
  - проверка сбалансированности целевой переменной (переменная не сбалансирована)
3. Исключен дисбаланас целевой переменной за счет удаления части "нетоксичных" строк.
Проведена подготовка данных к машинному обучению, тексты отчищены:
от повторяющих более 3-х раз подряд символов
от мусорных символов (;$& и т.д.)
от лишних пробелов
от стоп-слов
Тексты лемматизированы
Для текстов посчитаны матрицы TF-IDF (статистическая мера, используемая для оценки важности слова в контексте документа)
Размерность матрицы снижена за счет удаления редких слов (менее 3 вхождений)
Для текстов локально посчитаны и загружены через google-диск эмбендинги предъобученной модели BERT
Подготовлены функции, автоматизирующие:
предъобратотку текстов
расчет, считывание и запись эмбендингов
перебор гиперпараметров на основе метода GridSearch и кросс-валидации
фиксацию результатоввычислений в отдельных ДФ
Проведено машинное обучение, использованы модели:
LogisticRegression
RandomForestClassifier
HistGradientBoostingClassifie
KNeighborsClassifier
Подобраны гиперпараметры для указанных моделей, оценена метрика качества, полученная на обучающей выборке, модель с оптимальными гиперпараметрами проверены на тестовой выборке.
По результатам сравнение результатов, установлено, что лучшей моделью является LightGBM c F1 на тестовой выборке 0.78
Результаты визуализированы ROC_AUC кривой
