# Учебный проект модуля "Обучение с учителем". Прогнозирование оттока клиентов банка

## Цель проекта:
Создать модель, которая на основании исследования исторических данных о поведении клиентов и фактах расторжения договоров с банком предсказывает, уйдёт клиент из банка в ближайшее время или нет. Показателем качества модели принять F1-меру , которая не должна быть хуже 0.59.

## Задачи проекта:
- построить модель классификации для предсказания поведения клиента (уйдет, не уйдет);
- довести метрику качества модели (F1-меру) до 0.59;
- дополнительно отслеживать показатель метрики AUC-ROC.

## Описание данных:
По каждому клиенту доступны технические (уникальный идентификатор), персональные (фамилия, страна проживания, пол, возраст, предполагаемая зарплата) и банковские данные (кредитный рейтинг, сколько лет человек является клиентом банка, баланс на счёте, количество продуктов банка, используемых клиентом, наличие кредитной карты, наличие кредитной карты, активность клиента).

## Основные задачи исследования:
1. Провести предобработку данных
2. Изучить существующие зависимости между персональными и банковскими данными клиентов и фактами их ухода из банка.
3. Реализовать несколько алгоритмов исключения дисбаланса целевой переменной
4. Обучит несколько моделей машинного обучения, среди которых по валидационной выборке выбрать лучшую.
5. Сформировать выводы по результатам исследования

## В процессе исследования решены следующие задачи:
1. Загружены и изучены данные о клиентах банка
2. Загруженные данные оценены, определена их форма, типы, смысловая нагрузка
3. Выполнена предъобработка, включая:
     - проверку и переименование названий столбцов (приведение к стилю under_score)
     - проверку корректноти назначенных типов данных (некорректных назначений не выявлено)
     - поиск полных и неявных дубликатов (не выявлено) 
     - поиск и заполнение пропусков (найдены и заполненены медианными значениями схожих записей пропуски в столбце tenure c контролем статистических характеристик изменяемого признака)
     - выявление аномальных значений (не выявлено)
     - удаление неинформативных столбцов, затрудняющих обучение моделей ('row_number', 'customer_id', 'surname')
     - поиск коррелированых столбцов (не выявлено)
     - кодирование категориальных переменных (geography, gender)
4. Проведено исследование данных на предмет применимости для машинного обучения
  - изучены признаки (credit_score, geography, gender, age, tenure, balance, num_of_products, has_cr_card, is_active_member, estimated_salary) и целевые показатели (exited)
  - проведена нормализация количественных признаков методом preprocessing.MinMaxScaler
  - выполнено разбиение данных на тренировочную, валидационную и тестовую выборки
  - исследован балланс классов (выявлен дисбаланс в сторону Negative(0) значений целевого признака)
  - использовано два метода исключения дсбаланса данных
     - за счет добавления значений (клонирование записей с 1 целевым признаком)
     - за счет уменьшения количества значений (отбрасывание записей с 0 целевым признаком)
5. Подтотовлен комплект функций, автоматизирующих:
 - перебор гиперпараметров моделей
 - возвращающих лучшую модель, где лучшей считается модель с наивысшим значением f1-меры на валидационной выборке
 - расчитывающих и фиксирующих метрики модели в словаре - отчете

6. Проведено машинное обучение с учителем на моделях классификации:
- модель LinearDiscriminantAnalysis
- модель KNeighborsClassifier
- модель GaussianNB
- модель DecisionTreeClassifier (решающее дерево)
- модель RandomForestClassifier (случайный лес)
- модель LogisticRegression (лог-регрессия)

7. Выполнено:
   - обучение всех моделей на сбалансированной методом клонирования выборке
   - обучение всех моделей на сбалансированной методом отбрасывания выборке
   - обучение двух наиболее оптимальных моделей (DecisionTreeClassifier, RandomForestClassifier) на несбалансированной выборке
   - подбор порога принятия решения на несбалансированной выборке для двух наиболее оптимальных моделей (DecisionTreeClassifier, RandomForestClassifier), позволивший добиться f1-мера: 0.62 для несбалансированных данных на модели RandomForestClassifier
   - выбрана лучшая модель на основании метрик (F1-мера, AUC-ROC): RandomForestClassifier
   - финальное тестирование лучщей модели, в процессе которого достигнуты f1-мера: 0.653, auc-roc: 0.89 
   
8. По результатам обучения и сравнения моделей можно отметить следующее.
   1. Несмотря на принятые меры все модели на всех выборках склонны к переобучению
   2. Наиболее склонна к переобучению модель KNeighborsClassifier (осуществляет поиск по ближайшим соседям
   3. Применение балансировки методом клонирования позволяет добиться наилучщих показателей качества моделей (f1-мера)
   4. Метрика f1-мера очень сильно зависит от сбалансированности данных
   5. Метрика auc-roc менее зависима от типа балансировки выборки (различия между сбалансированной и не сбалансированной выборкой менее 0.02 пунктов).
   6. Из интересного: на тренировочной выборке самые лучщие результаты были достигнуты с моделью KNeighborsClassifier (auc-roc = 1). Но найти способ хоть как-то сохранить такие показатели для валидационной выборки не  удалось.
   
Все параметры и объекты обученных моделей зафиксированы в датафрейме report_df
